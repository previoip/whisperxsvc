<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>wxsvcv2</title>
  <style>

  </style>
</head>
<body>
   <input id="bToggle" type="button" value="start">
  <table id="tbTrans" style="width: 100%;">
    <colgroup>
      <col span="1" style="width: 10em;">
      <col span="1" style="width: 2em;">
      <col span="1" style="width: auto;">
    </colgroup>
    <thead>
      <tr>
        <th scope="col">ts</th>
        <th scope="col">lang</th>
        <th scope="col">text</th>
      </tr>
    </thead>
    <tbody>
    </tbody>
  </table>
  <script>


const RECORD_WINDOW = 5000;
const MEDIARECORDER_OPTIONS = {
  audioBitsPerSecond: 128000,
  // mimeType: "audio/ogg;codecs=vorbis" opus
};

const elBtnToggle = document.getElementById('bToggle');
const elTableBody = document.getElementById('tbTrans').getElementsByTagName('tbody')[0];
const wHost = window.location.hostname;
const wPort = window.location.port;


const states = {};
states.running = 0;

const handles = {};
handles.contTimeout = null;

const aAudioComp = {};
aAudioComp.src = null;
aAudioComp.ctx = null;
aAudioComp.analyzer = null;
aAudioComp.analyzerBuf = null;
aAudioComp.recorder = null;


function appInit() {
  navigator.mediaDevices.getUserMedia({audio: true})
  .then((stream)=>{
    aAudioComp.ctx = new (window.AudioContext || window.webkitAudioContext)();
    aAudioComp.src = aAudioComp.ctx.createMediaStreamSource(stream);
    aAudioComp.recorder = new MediaRecorder(stream, MEDIARECORDER_OPTIONS);
    aAudioComp.recorder.ondataavailable = (e)=>{
      wxclStageAndTransmit(e.data).then((d)=>{
        wxclRender(d);
      });
    };
    aAudioComp.ctx.suspend();
  })
  .catch((err)=>{
    appDestroy();
    console.error(err)
  })
};

function appDestroy() {
  if (aAudioComp.ctx !== null && aAudioComp.ctx.state !== "closed") {
    aAudioComp.ctx.close().then(() => {
      aAudioComp.ctx = null;
    })
  };
  aAudioComp.src = null;
  aAudioComp.analyzer = null;
  aAudioComp.analyzerBuf = null;
  aAudioComp.recorder = null;
};


async function wxclStageAndTransmit(payload) {
  const formData = new FormData()
  formData.append('file', payload, 'file')
  formData.append('ts', new Date().getTime())
  return fetch(`http://${wHost}:${wPort}/api/trans/a`, {
        method: 'POST',
        // headers: {
        //   Accept: 'application/json',
        //   'Content-Type': 'application/json',
        // },
        // enctype:"multipart/form-data",
        body: formData
  })
  .then(resp=>resp.json())
  .catch(console.error)
}


const insertCellOnRow = (row, ncol, str) => {
  row.insertCell(ncol).appendChild(document.createTextNode(str));
}

function wxclRender(data) {
  data?.trans?.forEach(trans => {
    trans?.segments?.forEach(seg => {
      let row = elTableBody.insertRow(0)
      insertCellOnRow(row, 0, seg['ts'])
      insertCellOnRow(row, 1, trans['language'])
      insertCellOnRow(row, 2, seg['text'])
    })
  });
}

function wxclStartCont() {
  wxclStop();
  setTimeout(wxclStart, 10);
  handles.contTimeout = setTimeout(wxclStartCont, RECORD_WINDOW);
};

function wxclStopCont() {
  if (handles.contTimeout !== null) {
    clearTimeout(handles.contTimeout);
    handles.contTimeout = null;
  }
  wxclStop();
};

function wxclStart() {
  if (states.running === 1) return;
  states.running = 1;
  elBtnToggle.value = 'stop'
  aAudioComp.ctx.resume();
  aAudioComp.recorder.start()
  // console.log('started')
};

function wxclStop() {
  if (states.running === 0) return;
  states.running = 0;
  elBtnToggle.value = 'start'
  aAudioComp.recorder.stop();
  aAudioComp.ctx.suspend();
  // console.log('stopped')
};


elBtnToggle.addEventListener('click', (e)=>{if (states.running === 0) {wxclStartCont()} else {wxclStopCont()};});
window.onbeforeunload = (e)=>{wxclStopCont();appDestroy()};

appInit();

  </script> 
</body>
</html>